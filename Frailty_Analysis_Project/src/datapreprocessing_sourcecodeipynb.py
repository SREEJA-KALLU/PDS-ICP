# -*- coding: utf-8 -*-
"""DataPreprocessing_SourceCodeipynb.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18wIZph6rZklDPjbAOGofZ8qdOHVsRU8S

#DATA TYPE CONVERSION
"""

# Commented out IPython magic to ensure Python compatibility.
# %%capture result_output_1
# import pandas as pd
# 
# # DataFrame
# data = {'Height': [65.8, 71.5, 69.4, 68.2, 67.8, 68.7, 69.8, 70.1, 67.9, 66.8],
#         'Weight': [112, 136, 153, 142, 144, 123, 141, 136, 112, 120],
#         'Age': [30, 19, 45, 22, 29, 50, 51, 23, 17, 39],
#         'Grip_strength': [30, 31, 29, 28, 24, 26, 22, 20, 19, 31],
#         'Frailty': ['N', 'N', 'N', 'Y', 'Y', 'N', 'Y', 'Y', 'N', 'N']}
# 
# df = pd.DataFrame(data)
# 
# # Converting 'Frailty' column from Y/N to 1/0
# df['Frailty'] = df['Frailty'].map({'Y': 1, 'N': 0})
# 
# print(df)
#

"""#DATA NORMALIZATION AND STANDARDIZATION

"""

# Commented out IPython magic to ensure Python compatibility.
# %%capture result_output_2
# # data
# data = {
#     'Height': [65.8, 71.5, 69.4, 68.2, 67.8, 68.7, 69.8, 70.1, 67.9, 66.8],
#     'Weight': [112, 136, 153, 142, 144, 123, 141, 136, 112, 120],
#     'Age': [30, 19, 45, 22, 29, 50, 51, 23, 17, 39],
#     'Grip_strength': [30, 31, 29, 28, 24, 26, 22, 20, 19, 31]
# }
# 
# # Normalization
# def normalize(column):
#     min_value = min(column)
#     max_value = max(column)
#     return [(x - min_value) / (max_value - min_value) for x in column]
# 
# # Standardization
# def standardize(column):
#     mean_value = sum(column) / len(column)
#     std_dev = (sum([(x - mean_value) ** 2 for x in column]) / len(column)) ** 0.5
#     return [(x - mean_value) / std_dev for x in column]
# 
# # Applying Normalization and Standardization
# normalized_data = {key: normalize(value) for key, value in data.items()}
# standardized_data = {key: standardize(value) for key, value in data.items()}
# 
# # Displaying results
# import pandas as pd
# normalized_df = pd.DataFrame(normalized_data)
# standardized_df = pd.DataFrame(standardized_data)
# 
# print("Normalized Data:")
# print(normalized_df)
# 
# print("\nStandardized Data:")
# print(standardized_df)
#

"""#OUTLIER DETECTION

"""

# Commented out IPython magic to ensure Python compatibility.
# %%capture result_output_3
# import numpy as np
# import pandas as pd
# from scipy import stats
# 
# # data
# data = {
#     'Height': [65.8, 71.5, 69.4, 68.2, 67.8, 68.7, 69.8, 70.1, 67.9, 66.8],
#     'Weight': [112, 136, 153, 142, 144, 123, 141, 136, 112, 120],
#     'Age': [30, 19, 45, 22, 29, 50, 51, 23, 17, 39],
#     'Grip_strength': [30, 31, 29, 28, 24, 26, 22, 20, 19, 31]
# }
# 
# df = pd.DataFrame(data)
# 
# # Z-score calculation
# z_scores = np.abs(stats.zscore(df))
# 
# # Setting a threshold for the Z-score that is 3
# threshold = 3
# 
# # Finding data points where any Z-score value exceeds the threshold
# outliers = df[(z_scores > threshold).any(axis=1)]
# 
# # Displaying the outliers
# print("Outliers:")
# print(outliers)
# 
#

"""#CAPTURING RESULTS INTO A TEXT FILE"""

with open('datapreprocessing_result.txt', 'w') as f:

    f.write(result_output_1.stdout + '\n')
    f.write(result_output_2.stdout + '\n')
    f.write(result_output_3.stdout + '\n')

from google.colab import files
files.download('datapreprocessing_result.txt')